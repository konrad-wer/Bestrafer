% Opcje klasy 'iithesis' opisane sa w komentarzach w pliku klasy. Za ich pomoca
% ustawia sie przede wszystkim jezyk i rodzaj (lic/inz/mgr) pracy, oraz czy na
% drugiej stronie pracy ma byc skladany wzor oswiadczenia o autorskim wykonaniu.
\documentclass[declaration,shortabstract,english]{iithesis}

\usepackage[utf8]{inputenc}

%%%%% DANE DO STRONY TYTUŁOWEJ
% Niezaleznie od jezyka pracy wybranego w opcjach klasy, tytul i streszczenie
% pracy nalezy podac zarowno w jezyku polskim, jak i angielskim.
% Pamietaj o madrym (zgodnym z logicznym rozbiorem zdania oraz estetyka) recznym
% zlamaniu wierszy w temacie pracy, zwlaszcza tego w jezyku pracy. Uzyj do tego
% polecenia \fmlinebreak.
\polishtitle    {Wymagający złamania wierszy\fmlinebreak tytuł pracy w~języku polskim}
\englishtitle   {English title}
\polishabstract {\ldots}
\englishabstract{\ldots}
% w pracach wielu autorow nazwiska mozna oddzielic poleceniem \and
\author         {Konrad Werbliński}
% w przypadku kilku promotorow, lub koniecznosci podania ich afiliacji, linie
% w ponizszym poleceniu mozna zlamac poleceniem \fmlinebreak
\advisor        {dr Filip Sieczkowski}
%\date          {}                     % Data zlozenia pracy
% Dane do oswiadczenia o autorskim wykonaniu
%\transcriptnum {}                     % Numer indeksu
%\advisorgen    {dr. Jana Kowalskiego} % Nazwisko promotora w dopelniaczu
%%%%%

%%%%% WLASNE DODATKOWE PAKIETY
%
%\usepackage{graphicx,listings,amsmath,amssymb,amsthm,amsfonts,tikz}
\let\lll\undefined
\usepackage{mathtools, array, amsfonts, mathpartir, amssymb, stmaryrd}
\usepackage[nottoc]{tocbibind}

%
%%%%% WŁASNE DEFINICJE I POLECENIA
%
%\theoremstyle{definition} \newtheorem{definition}{Definition}[chapter]
%\theoremstyle{remark} \newtheorem{remark}[definition]{Observation}
%\theoremstyle{plain} \newtheorem{theorem}[definition]{Theorem}
%\theoremstyle{plain} \newtheorem{lemma}[definition]{Lemma}
%\renewcommand \qedsymbol {\ensuremath{\square}}

\newenvironment{grammar}[2]
 {\begin{tabular}{@{\qquad}>{$}l<{$}@{\qquad}l@{}}
  \multicolumn{1}{@{}l@{}}{$#1$}&\multicolumn{1}{l@{}}{\hspace{-2em}#2}\\}
 {\end{tabular}}

%%%%%

\begin{document}

%%%%% POCZĄTEK ZASADNICZEGO TEKSTU PRACY

\chapter{Introduction}
\chapter{Language description}
\section{Language features}
Bestrafer's syntax was designed to be concise, expressive, readable and beautiful.
It was strongly influenced by Haskell, but modified to be indentation-insensitive for greater
flexibility in writing beautiful code and ease of parsing.
\begin{verbatim}
//Single-line comment
/*
  Multi-line comment
*/

def fac :: Int -> Int
def fac 0 = 1
def fac n = n * fac (n - 1)

def ack :: Int -> Int -> Int
def ack m n = case (m, n) of
  | (0, n) -> n + 1
  | (m, 0) -> ack (m - 1) 1
  | (m, n) -> ack (m - 1) (ack m (n - 1))

def main :: ()
def main =
  printInt (fac 5) `seq`
  printInt (ack 3 1)
\end{verbatim}
Our language supports Haskell-like top-level pattern matching in definitions. Type annotations
for top-level definitions are obligatory due to bidirectionality of the type system.
We use call-by-value evaluation strategy like many mainstream functional languages.
Program is evaluated from the top to the bottom of the source file
(with a minor subtlety broader described in the chapter 4). All of the definitions on the top-level
are mutually recursive. One can also define nested functions using \verb+rec+ keyword.
\begin{verbatim}
def fib :: Int -> Int
def fib n =
  rec :: (Int, Int) -> Int -> Int :
    f lasts n = case n of
      | 0 -> fst lasts
      | n -> f (snd lasts, fst lasts + snd lasts) (n - 1)
  in f (0, 1) n
\end{verbatim}

Bestrafer supports all of the typical IO operations including reading and writing files as well as
parsing and printing values of primitive types from and to standard input-output.
IO operations may be performed at any point in program, following the style of
several languages in the ML family. It also supports exception handling with \verb+error+
keyword for throwing errors and \verb+try-catch+ block for catching
user thrown (\verb+RuntimeException+) and builtin (\verb+IOException+,
\verb+ArithmeticException+) exceptions. We can use optional variable in exception pattern
for extracting the error message.
\begin{verbatim}
def checkPassword :: String -> ()
def checkPassword s =
  if s == "Rammstein" then
    ()
  else
    error: "Password is incorrect"

def main :: ()
def main =
  try:
    let password = getLine () in
    checkPassword password `seq`
    let x = readLnInt () in
    printInt (1000 / x) `seq`
    let filename = getLine () in
    readFile filename |> putStrLn
  catch:
    | IOException e -> putStrLn e
    | ArithmeticException -> putStrLn "Division by zero"
    | RuntimeException e -> putStrLn e
    | Exception e -> putStrLn e
\end{verbatim}

Bestrafer allows user to define his own generalized algebraic data types (GADTs)
using the \verb+data+ keyword. There are two kinds of parameters in GADT definition:
\begin{itemize}
  \item named (denoted with a name starting with \verb+'+ followed by a capital letter) which work
        exactly like parameters of standard algebraic data types in languages like Haskell or OCaml.
  \item unnamed (denoted with their kind: \verb+*+ or \verb+N+) which may be set by the user to any type
        of the specified kind, thus providing GADT functionality.
\end{itemize}
\begin{verbatim}
data Maybe 'A where
  | Nothing :: Maybe 'A
  | Just :: 'A -> Maybe 'A
\end{verbatim}
Our language also supports defining data types without value constructors, which may be used as annotations in GADTs,
like types \verb+Ok+ and \verb+Fail+ used to annotate type \verb+Either+ in the following example.
\begin{verbatim}
data Ok
data Fail

data Either * 'A 'B where
  | Left  :: 'A -> Either Fail 'A 'B
  | Right :: 'B -> Either Ok 'A 'B
\end{verbatim}
A flagship data type of Bestrafer language is a list indexed by its length, traditionally called \verb+Vec+.
\begin{verbatim}
data Vec N 'A where
  | []  :: Vec 0 'A
  | (:) :: forall n : N . 'A -> Vec n 'A -> Vec (S n) 'A
\end{verbatim}
Using the above definition we can write \verb+map+ function, which type encodes the proof that the resulting \verb+Vec+ has the same
length as the input one.
\begin{verbatim}
def map :: forall n : N, a : *, b : * .
  (a -> b) ->
  Vec n a ->
  Vec n b
def map _ [] = []
def map f (x : xs) = f x : map f xs
\end{verbatim}
To give programmer full flexibility and expressive power our language also has a standard non-indexed \verb+List+ data type.
\begin{verbatim}
data List 'A where
  | {}  :: List 'A
  | (;) :: 'A -> List 'A -> List 'A
\end{verbatim}

Bestrafer also supports existential types, but unlike in Haskell and OCaml their usage is not tied to data types declarations.
Instead they can be used freely like any other type constructor. The following implementation of a \verb+filter+ function
(taken from Bestrafer's standard library) utilizes existential type to express the fact that we cannot predict length of
the resulting \verb+Vec+. We use \verb+let+ expression to unpack result of recursive call from the existential type, thus
ensuring that the type variable describing length of \verb+tail+ is inserted to the context before the subtyping starts.
\begin{verbatim}
def filter :: forall n : N, a : * .
  (a -> Bool) ->
  Vec n a ->
  exists k : N . Vec k a
def filter _ [] = []
def filter p (x : xs) =
  let tail = filter p xs in
  if p x then
    x : tail
  else
    tail
\end{verbatim}

Quantifiers are always explicit to enforce conscious kind specification and emphasize connection to a type theoretic core.
To articulate this connection even more instead of writing \verb+forall+, \verb+exists+ and \verb+\x -> x+ one can write
$\forall$, $\exists$ and $\lambda$ \verb+x -> x+.
\section{GADT examples}
\subsection*{Matrix algebra}
We can make a great use of Bestrafer's indexed \verb+Vec+ type to implement matrix algebra operations.
Now the types provide the proof that the matrix operations that we defined produce results with
correct dimensions and impose restriction on input arguments which ensures that they also have
proper dimensions.
\begin{verbatim}
def mult :: forall n : N, m : N, k : N .
  Vec (S n) (Vec (S m) Int) ->
  Vec (S m) (Vec (S k) Int) ->
  Vec (S n) (Vec (S k) Int)
def mult a b = map ((flip multVec) b) a

def multVec :: forall n : N, m : N .
  Vec (S n) Int ->
  Vec (S n) (Vec (S m) Int) ->
  Vec (S m) Int
def multVec v m =
  map (foldl1 (\x y -> x + y))
  (map (zipWith (\x y -> x * y) v) (transpose m))

def transpose :: forall n : N, m : N .
  Vec (S n) (Vec (S m) Int) ->
  Vec (S m) (Vec (S n) Int)
def transpose matrix =
  let indices = mapi const (head matrix) in
  map (flip column matrix) indices

def column :: forall n : N, m : N .
  Int ->
  Vec (S n) (Vec (S m) Int) ->
  Vec (S n) Int
def column i = map (nth i)

def nth :: forall n : N, a : * . Int -> Vec (S n) a -> a
def nth 0 (x : xs) = x
def nth _ [x] = x
def nth n (x1 : x2 : xs) = nth (n - 1) (x2 : xs)
\end{verbatim}
One could think that the above functions are only useful for some statically defined values,
since we cannot predict dimensions of \verb+Vec+s which come from IO. But, that is not true!
We can use them in program that reads matrices from IO, but we have to prove, that we handle
all cases of invalid input before passing it into our matrix algebra functions.

\subsection*{Statically typed printf function\cite{inproceedings}}
The well-known \verb+printf+ function from the C programming language,
uses a string to provide formating of a printed text. However, this approach
has a major drawback: formated arguments are not statically type checked.
As a result of that, writing \verb+printf("%d", 3.14);+ will print meaningless int,
without emiting any warning or error. That's where the GADTs come to the rescue. In the following
example, we define \verb+Format+ data type which is used to express intended formating of a
printed string. By chaining constructors together we define type of intended printing function,
which is accumulated in unnamed parameter of the \verb+Format+ data type. When a value of
the type \verb+Format+ is applied to the function \verb+printf+, an appropriate printing function
is built by step by step deconstruction of the \verb+Format+ value. By combining this approach
with the function composition operator (.) (for writing more readable chains of constructors),
we get a neat and type-safe way of pretty-printing values into the standard output.
\begin{verbatim}
data Format * where
  | Str :: forall a : * . Format a -> Format (String -> a)
  | Inr :: forall a : * . Format a -> Format (Int -> a)
  | Flt :: forall a : * . Format a -> Format (Float -> a)
  | Bl  :: forall a : * . Format a -> Format (Bool -> a)
  | Chr :: forall a : * . Format a -> Format (Char -> a)
  | Lit :: forall a : * . String -> Format a -> Format a
  | Eol :: forall a : * . Format a -> Format a
  | End :: Format ()

def printf ::  forall a : * . Format a -> a
def printf End = ()
def printf (Lit s format) = putStr s `seq` printf format
def printf (Eol format) = putStrLn "" `seq` printf format
def printf (Str format) =
  \x -> putStr x `seq` printf format
def printf (Inr format) =
  \x -> (putStr . intToString) x `seq` printf format
def printf (Flt format) =
  \x -> (putStr . floatToString) x `seq` printf format
def printf (Bl  format) =
  \x -> (putStr . boolToString) x `seq` printf format
def printf (Chr format) =
  \x -> putChar x `seq` printf format

def main :: ()
def main =
  putStrLn "What is your name ?" `seq`
  let name = getLine () in
  printf ((Lit "Hello " . Str . Lit "!" . Eol .
           Lit "The answer is: " . Inr . Eol) End) name 42
\end{verbatim}

\chapter{Type system}
\section{Dunfield's and Krishnaswami's system}

\subsection*{Typing and subtyping rules}

\section{Our variant of the system}
We made some necessary modification to the type system to make our language useful and user friendly.
First of all we added typing rules for simple types such as
\verb+Int+ or \verb+String+, operators, \verb+if+ statements, \verb+let+ expressions,
\verb+error+ throwing and \verb+try+ - \verb+catch+ blocks, but we omit them in this paper because
they are not interesting and straightforward. However, it is important to remark, that \verb+let+ expression unpacks the
existential types which is necessary to ensure correct order of inserting type variables to the context while defining
recursive functions. We also added extra inference rules following the style of Dunfield and Krishnaswami [2013] \cite{Dunfield13:bidir},
to mimize boilerplate type annotations and produce better quality typechecking errors. Following
remark of Dunfield and Krishnaswami [2019] \cite{gadt-popl19} we extended subtyping to functions and propositional types.
The biggest modification is the introduction of user defined generalized algebraic data types. The last section
of this chapter covers exhaustively typing rules and implementation details of GADTs. We discarded separate rules for
\verb+Vec+, treating it like any other GADT.

\subsection*{Types, monotypes and propositions}

We distinguish between types (for clarity sometimes called big types) and monotypes.
Basically monotypes are just simplified types (whithout quantification and propositional types) plus
inhabitants of kind $\mathbb{N}$ (namely zero - \verb+0+ and successor - \verb+S+).
As we can see from the following definition quantification and propositions are restricted to monotypes.
However use cases for polymorphism on big types seem to be rare in practice. Moreover our extended subtyping
reduces number of programs which would not typecheck due to this restriction.

\textbf{Kinds:}

\begin{grammar}{\kappa \Coloneqq}{}
  \star \mid \mathbb{N}
\end{grammar}

\textbf{Types:} (big types)

\begin{grammar}{A,B,C\Coloneqq}{}
  \verb+()+ \mid \verb+Bool+ \mid \verb+Int+ \mid \verb+Float+  \mid \verb+Char+ \mid \verb+String+ & simple types\\
  \mid  A_1 \times A_2 \times \dots \times A_n & product\\
  \mid \alpha                           & universal variable\\
  \mid  \hat{\alpha}                    & existential variable\\
  \mid \forall t \colon \kappa. A       & universal quantification\\
  \mid \exists t \colon \kappa. A       & existential quantification\\
  \mid P \supset A                      & guarded type\\
  \mid A \wedge  P                      & asserting type\\
  \mid \textit{Type identifier } \rho_1  \rho_2  \dots \rho_n              & user defined GADT
\end{grammar}

\textbf{GADT parameters:}

\begin{grammar}{\rho \Coloneqq}{}
  A \mid n                              & type or monotype
\end{grammar}

\textbf{Monotypes:}

\begin{grammar}{t,n\Coloneqq}{}
  0                                & zero\\
  \mid S \, n                              & successor of n\\
  \mid \verb+()+ \mid \verb+Bool+ \mid \verb+Int+ \mid \verb+Float+  \mid \verb+Char+ \mid \verb+String+ & simple types\\
  \mid  t_1 \times t_2 \times \dots \times t_n & product\\
  \mid \alpha                           & universal variable\\
  \mid  \hat{\alpha}                    & existential variable\\
  \mid \textit{Type identifier } t_1  t_2  \dots t_n              & user defined GADT
\end{grammar}

\textbf{Propositions:}

\begin{grammar}{P,Q\Coloneqq}{}
  t = t`
\end{grammar}

\subsection*{Higher rank polymorphism}
One of the key features of the Dunfield's and Krishnaswami's system is higher rank polymorphism.
Polymorphic types are treated like any other big type so they can be nested in each ohter arbitrarily
many times. The following example uses higher rank universal quantification in GADT constructor
to implement Scott's encoding of lists as a two continuations\cite{rankNtypes}.
\begin{verbatim}
data ListS 'A where
  | ListS :: (forall r : * .
             ('A -> ListS 'A -> r) ->r -> r) ->
             ListS 'A

def nil :: forall a : * . ListS a
def nil = ListS (\co ni -> ni)

def cons :: forall a : * . a -> ListS a -> ListS a
def cons x xs = ListS (\co ni -> co x xs)

def uncons :: forall a : *, r : * .
  (a -> ListS a -> r) -> r -> ListS a -> r
def uncons co ni (ListS f) = f co ni
\end{verbatim}
Bestrafer also allows higher rank existential quantification as the following example shows.
\begin{verbatim}
def heads :: forall n : N, a : * .
  Vec n (exists m : N . Vec (S m) a) ->
  Vec n a
def heads [] = []
def heads (x : xs) = head x : heads xs
\end{verbatim}

\subsection*{Guarded types and asserting types}
Bestrafer supports guarded types $P \supset A $ (\textit{$P$ implies $A$})
and asserting types $A \wedge  P$ (\textit{$A$ with $P$}).
Although the usage of propositions is in most cases implicit and hidden in typechecking GADTs,
there are some use cases for propositional types.
The following example uses guarded types to express GADT in continuation passing style\cite{rankNtypes}.

\begin{verbatim}
data SomeC * where
  | SomeC :: forall a : *. (forall r : * .
             (a = Int => Int -> r) ->
             (a = String => String -> r) ->
             (a -> r) -> r) -> SomeC a

def int :: Int -> SomeC Int
def int x = SomeC (\i s o -> i x)

def string :: String -> SomeC String
def string x = SomeC (\i s o -> s x)

def other :: forall a : * . a -> SomeC a
def other x = SomeC (\i s o -> o x)

def unsome :: forall a : *, r : * .
  (Int -> r) ->
  (String -> r) ->
  (a -> r) ->
  SomeC a -> r
def unsome i s o (SomeC f) = f i s o

def main :: ()
def main =
  let x = other 3.14 in
  printInt <| unsome id intFromString floatToInt x
\end{verbatim}

\subsection*{Extended subtyping}
We added extra subtyping rules to improve flexibility and expressiveness of the type system.
Without these rules the above example would not work, since we wouldn't be able to subtype
\verb+(Int -> r) +$<$ \verb+(a = Int => Int -> r)+.
\subsubsection*{Function subtyping:}
\begin{mathpar}
\inferrule{\Gamma \vdash A' \le^+ A \dashv \Theta \\
           \Theta \vdash [\Theta]B \le^- [\Theta]B' \dashv \Delta}
           {\Gamma \vdash A \rightarrow B \le^- A' \rightarrow B' \dashv \Delta}
\end{mathpar}
\subsubsection*{Propositional types subtyping:}
\begin{mathpar}
\inferrule{B \: not \: guarded \\ \Gamma \vdash P \: true \dashv \Theta \\
           \Theta \vdash [\Theta]A \le^- [\Theta]B \dashv \Delta}
           {\Gamma \vdash P \supset A \le^- B \dashv \Delta} \and
\inferrule{\Gamma, \, _{\blacktriangleright P} / P \dashv \Theta \\
           \Theta \vdash [\Theta]A \le^- [\Theta]B \dashv \Delta , \, _{\blacktriangleright P}, \, \Delta'}
           {\Gamma \vdash A \le^- P \supset B \dashv \Delta} \and
\inferrule{\Gamma, \, _{\blacktriangleright P} / P \dashv \bot}
          {\Gamma \vdash A \le^- P \supset B \dashv \Gamma} \and
\inferrule{\Gamma, \, _{\blacktriangleright P} / P \dashv \Theta \\
           \Theta \vdash [\Theta]A \le^+ [\Theta]B \dashv \Delta , \, _{\blacktriangleright P}, \, \Delta'}
           {\Gamma \vdash A \wedge P \le^+ B \dashv \Delta} \and
\inferrule{\Gamma, \, _{\blacktriangleright P} / P \dashv \bot}
          {\Gamma \vdash A \wedge P \le^+ B \dashv \Gamma} \and \and
\inferrule{A \: not \: asserting \\ \Gamma \vdash P \: true \dashv \Theta \\
           \Theta \vdash [\Theta]A \le^+ [\Theta]B \dashv \Delta}
           {\Gamma \vdash A \le^+ B \wedge P \dashv \Delta} \and
\end{mathpar}
\section{Our contribution - user defined GADTs}

\subsection*{Named and unnamed parameters}
Let's take a look again at the definition of data type \verb+Vec+:
\begin{verbatim}
data Vec N 'A where
  | []  :: Vec 0 'A
  | (:) :: forall n : N . 'A -> Vec n 'A -> Vec (S n) 'A
\end{verbatim}
One could wonder why do we need named parameters in our type system.
Couldn't we just use unnamed parameters and quantifiers, like in the example below ?
\begin{verbatim}
data Vec N * where
  | []  :: forall a : * . Vec 0 a
  | (:) :: forall n : N, a : * . a -> Vec n a -> Vec (S n) a
\end{verbatim}
That's true, we can define \verb+Vec+ like that, but there is a drawback to that approach. Since we are using
quantification on \verb+a+, our definition of \verb+Vec+ is restricted to monotypes, so, for example, we wouldn't be
able to typecheck vector of mixed length vectors: \verb+Vec n (exists m : N . Vec m a)+. That's where
named parameters come into play. They are capable of storing big types,
but that also means that they cannot be involved in type equations. As we can see, the combination of both kinds
of parameters is essential to provide full expressive power to the programmer.

\subsection*{Building and typechecking constructors}
We build GADT representations between parsing and typechecking process. We start by checking well-formedness of
constructors. We define well formed constructor in the following manner:

$Well \: formed \: constructor ::= Universal$

\begin{grammar}{Universal\Coloneqq}{}
  \forall \alpha : \kappa \,.\, Universal
  \mid Arrow
\end{grammar}

\begin{grammar}{Arrow\Coloneqq}{}
  A \rightarrow Arrow
  \mid Well \: formed \: result \: type
\end{grammar}\bigskip\\
By $Well \: formed \: result \: type$ we mean the type that matches type signature of currently defined GADT,
where positions of named parameters and kinds of types associated with unnamed parameters also match the type signature.
After that we build two representations of each constructor: template representation which is used when we check constructor
expression against known GADT type and functional which is used in all other cases (namely, partial application and passing
constructor as an argument to a function).

\subsubsection*{Template representation}
For the purpose of template representation we defined type templates, which basically are types with indexed holes,
which may be filled with any big type or monotype.

\textbf{Type templates:}

\begin{grammar}{A_\dagger,B_\dagger,C_\dagger\Coloneqq}{}
  \verb+()+ \mid \verb+Bool+ \mid \verb+Int+ \mid \verb+Float+  \mid \verb+Char+ \mid \verb+String+ & simple types\\
  \mid  A_{\dagger1} \times A_{\dagger2} \times \dots \times A_{\dagger n} & product\\
  \mid \alpha                                                                                   & universal variable\\
  \mid  \hat{\alpha}                                                                            & existential variable\\
  \mid \forall t \colon \kappa. A_\dagger                                                       & universal quantification\\
  \mid \exists t \colon \kappa. A_\dagger                                                       & existential quantification\\
  \mid P_\dagger \supset A_\dagger                                                              & guarded type\\
  \mid A_\dagger \wedge  P_\dagger                                                              & asserting type\\
  \mid \textit{Type identifier } \rho_{\dagger1}  \rho_{\dagger2}  \dots \rho_{\dagger n}       & user defined GADT \\
  \mid 1,2,3,\dots         & index of GADT parameter
\end{grammar}

\textbf{GADT parameter templates:}

\begin{grammar}{\rho \Coloneqq}{}
  A_\dagger \mid n_\dagger                        & type template or monotype template
\end{grammar}

\textbf{Proposition templates:}

\begin{grammar}{P_\dagger,Q_\dagger\Coloneqq}{}
  t_\dagger = t`_\dagger
\end{grammar}\bigskip\\
We define monotype templates similarly to big type templates, so we omit the formal definition for space reasons.

Template representation consists of list of universally quantified variables, list of propositions and list of constructor
arguments represented as type templates. We substitute named parameters identifiers and unnamed parameters in the result type with
\textit{parameters indices}, which correspond to adequate parameters in the type signature.
We generate propositions automatically based on constructor's result type.

When typechecking a constructor, we start by checking if its result type matches the type against which we are typechecking.
Then we check the arity of the constructor.
After that we substitute constructor's universally quantified variables with fresh existential variables.
Then we convert arguments' type templates and propositions' templates to types, monotypes and propositions
by replacing parameters' indices with types and monotypes from checked type parameters.
Next, we check propositions. Finally, we check constructor's arguments against generate types.
The following, quite lenghty, rule describes that process in the formal way:

\begin{mathpar}
\inferrule{typeName_{constrName} = typeName \\
  \alpha_1, \alpha_2, \dots, \alpha_m \shortleftarrow uvars_{constrName} \\
  P_{\dagger1}, P_{\dagger2}, \dots, P_{\dagger l} \shortleftarrow props_{constrName} \\
  A_{\dagger1}, A_{\dagger2}, \dots, A_{\dagger k} \shortleftarrow args_{constrName} \\
  P'_{\dagger1}, P'_{\dagger2}, \dots, P'_{\dagger l} \leftarrow
  [\hat{\alpha}_1 / \alpha_1, \hat{\alpha}_2 / \alpha_2, \dots, \hat{\alpha}_m / \alpha_m]
  P_{\dagger1}, P_{\dagger2}, \dots, P_{\dagger l}\\
  P_1, P_2, \dots, P_l \shortleftarrow [\rho_1 / 1, \rho_2 / 2, ... , \rho_n / n]
  P'_{\dagger1}, P'_{\dagger2}, \dots, P'_{\dagger l}\\
  A'_{\dagger1}, A'_{\dagger2}, \dots, A'_{\dagger k} \leftarrow
  [\hat{\alpha}_1 / \alpha_1, \hat{\alpha}_2 / \alpha_2, \dots, \hat{\alpha}_m / \alpha_m]
  A_{\dagger1}, A_{\dagger2}, \dots, A_{\dagger k}\\
  A_1, A_2, \dots, A_k \shortleftarrow [\rho_1 / 1, \rho_2 / 2, ... , \rho_n / n]
  A'_{\dagger1}, A'_{\dagger2}, \dots, A'_{\dagger k}\\
  \Gamma \vdash P_1 \: true \dashv \Theta_1\\
  \Theta_1 \vdash P_2 \: true \dashv \Theta_2\\
  \cdots \\ \Theta_{l-1} \vdash P_l \: true \dashv \Theta_l\\
  \Theta_l \vdash e_1 \Leftarrow [\Theta_l]A_1 \dashv \Delta_1\\
  \Delta_1 \vdash e_2 \Leftarrow [\Delta_1]A_2 \dashv \Delta_2\\
  \cdots \\ \Delta_{k-1} \vdash e_k \Leftarrow [\Delta_{k-1}]A_k \dashv \Delta_k
  }
  {\Gamma \vdash constrName \; e_1 \, e_2 \, \dots \, e_k
  \Leftarrow typeName \; \rho_1 \, \rho_2 \, \dots \, \rho_n \dashv \Delta_k}
\end{mathpar}

\subsubsection*{Functional representation}
Supplementary to the template representation, we represent constructors as a polymorphic functions.
To build functional representation we change named parameters into universally quantified variables.
For example cons of \verb+Vec+:
\begin{verbatim}
(:) :: forall n : N . 'A -> Vec n 'A -> Vec (S n) 'A
\end{verbatim}
is represented as:
\begin{verbatim}
(:) :: forall a : *, n : N . a -> Vec n a -> Vec (S n) a
\end{verbatim}
Since we are using universal quantification on all parameters,
when using functional representation every parameter must by monotype.
This is why we put so much effort into creating template representation based on named
parameters.

\chapter{Remarks on semantics}
\section{Function definitions}
\section{GADT constructors}
\section{Evaluation order}

\chapter{Future work}

%%%%% BIBLIOGRAFIA

\bibliographystyle{unsrt}
\bibliography{biblo.bib}

\end{document}
