% Opcje klasy 'iithesis' opisane sa w komentarzach w pliku klasy. Za ich pomoca
% ustawia sie przede wszystkim jezyk i rodzaj (lic/inz/mgr) pracy, oraz czy na
% drugiej stronie pracy ma byc skladany wzor oswiadczenia o autorskim wykonaniu.
\documentclass[declaration,shortabstract,english]{iithesis}

\usepackage[utf8]{inputenc}

%%%%% DANE DO STRONY TYTUŁOWEJ
% Niezaleznie od jezyka pracy wybranego w opcjach klasy, tytul i streszczenie
% pracy nalezy podac zarowno w jezyku polskim, jak i angielskim.
% Pamietaj o madrym (zgodnym z logicznym rozbiorem zdania oraz estetyka) recznym
% zlamaniu wierszy w temacie pracy, zwlaszcza tego w jezyku pracy. Uzyj do tego
% polecenia \fmlinebreak.
\polishtitle    {Implementacja funkcyjnego języka programowania z polimorfizmem wyższego rzędu oraz
uogólnionymi algebraicznymi typami danych}
\englishtitle   {Implementation of a functional programming language with higher-rank polymorphism and
generalized algebraic data types}
\polishabstract {
W ostatnich latach uogólnione algebraiczne typy danych zyskały dużą popularność w świecie funkcyjnych
języków programowania. Znacznie zwiększają one ekspresywność systemu typów oraz umożliwiają dowodzenie
statycznych właściwości programów.

Przedstawiamy funkcyjny język programowania Bestrafer wykorzystujący nowatorskie podejście
do uogólnionych typów algebraicznych zapropne niedawno przez
Joshua'e Dunfield'a and Neelakantan'a R. Krishnaswami'ego.
W tej pracy opisujemy nasz język oraz omawiamy nasz wkład w implementację oraz
rozszerzenie systemu typów Dunfield'a and Krishnaswami'ego.
}
\englishabstract{
Generalized algebraic data types have gained a lot of attention in the functional programming community
over the last two decades. They greatly extend expressivity of the type system
and allow to prove static properties of programs.

We introduce Bestrafer - a functional programming language utilizing a novel approach to GADTs
recently proposed by Joshua Dunfield and Neelakantan R. Krishnaswami.
In this thesis we present our language and discuss our contribution
in extending and implementing Dunfield and Krishnaswami's type system.
}
% w pracach wielu autorow nazwiska mozna oddzielic poleceniem \and
\author         {Konrad Werbliński}
% w przypadku kilku promotorow, lub koniecznosci podania ich afiliacji, linie
% w ponizszym poleceniu mozna zlamac poleceniem \fmlinebreak
\advisor        {dr Filip Sieczkowski}
%\date          {}                     % Data zlozenia pracy
% Dane do oswiadczenia o autorskim wykonaniu
%\transcriptnum {}                     % Numer indeksu
%\advisorgen    {dr. Jana Kowalskiego} % Nazwisko promotora w dopelniaczu
%%%%%

%%%%% WLASNE DODATKOWE PAKIETY
%
%\usepackage{graphicx,listings,amsmath,amssymb,amsthm,amsfonts,tikz}
\let\lll\undefined
\usepackage{mathtools, array, amsfonts, mathpartir, amssymb, stmaryrd, cancel}
\usepackage[nottoc]{tocbibind}

%
%%%%% WŁASNE DEFINICJE I POLECENIA
%
%\theoremstyle{definition} \newtheorem{definition}{Definition}[chapter]
%\theoremstyle{remark} \newtheorem{remark}[definition]{Observation}
%\theoremstyle{plain} \newtheorem{theorem}[definition]{Theorem}
%\theoremstyle{plain} \newtheorem{lemma}[definition]{Lemma}
%\renewcommand \qedsymbol {\ensuremath{\square}}

\newenvironment{grammar}[2]
 {\begin{tabular}{@{\qquad}>{$}l<{$}@{\qquad}l@{}}
  \multicolumn{1}{@{}l@{}}{$#1$}&\multicolumn{1}{l@{}}{\hspace{-2em}#2}\\}
 {\end{tabular}}

%%%%%

\begin{document}

%%%%% POCZĄTEK ZASADNICZEGO TEKSTU PRACY

\chapter{Introduction}
Mainstream functional programming languages such as Haskell or OCaml use type systems
based on Hindley-Milner\cite{Hindley,Milner} system.
It supports full type inference for languages with parametric polymorphism.
However, in its standard form, Hindley-Milner enables only rank-1 polymorphism, which means that quantifiers may only
occur on the outside of type. In this system, types are divided into monotypes and polytypes,
where polytypes are superset of monotypes, that also includes universal quantifiers.
Type variables may only by instantiated with monotypes. Milner provided efficient
method of inference for this system called algorithm W\cite{Milner}.
Notable features of Hindley-Milner are completeness and ability to infer the most general type
without any type annotations provided by a programmer.

Generalized algebraic data types (GADTs)\cite{grd,fcpt} have received lot of recognition in
the functional programming world in recent years. They enable value constructors to return specific, rather
then parametric instances of their own data types. For instance, in the following example, we define
constructors which produce specific instances of the \verb+Value+ data type.
\begin{verbatim}
data Value * where
  | F :: Float -> Value Float
  | I :: Int -> Value Int
  | B :: Bool -> Value Bool
\end{verbatim}
This provides greater flexibility and expressivity of the type system,
but also allows to statically prove correctness of invariants and properties of functions.
For example, we can utilize expressive power of GADTs to implement statically type checked \verb+printf+ function
or to prove that matrix algebra functions produce results of correct dimensions. Another desirable type system
features are higher-rank polymorphism and existential types. Rank-n polymorphism allows to nest quantifiers
arbitrarily deep, which greatly improves expressivity of the type system. Existential types are extremely useful
in combination with indexed types, for example allowing convenient programming with length indexed lists.

However, type inference for GADTs in languages like OCaml is difficult\cite{ocaml-gadts}.
Moreover, complete type inference for laguages with higher-rank polymorphism is undecidable, thus it is required to
provide some type-annotations to guide the type system and make the problem decidable. This made us use a different solution,
namely bidirectional type checking\cite{PierceTurnerBidType}. This approach combines two mutually recursive judgements,
type inference (synthesis) and checking against known type.

Bidirectional type checking found many applications in a wide-spectrum of programming languages, ranging from
imperative, object-oriented laguages like C\# \cite{csharp2,csharp3} to type checking dependent types\cite{Coquand}
and even to some extent in the GHC compiler of the Haskell programming language for type checking rank-n types\cite{peytonjones}.
This technique allows one to define elegant and understandable type systems and scales well with new features added to the
language. Bidirectional systems also provide good quality error messages, in contrast to sometimes incomprehensible type errors
in inference based type system implementations.

We follow the innovative approach of Joshua Dunfield and Neelakantan R. Krishnaswami\cite{gadt-popl19} to create Bestrafer -
a call-by-value functional programming language with higher-rank polymorphism,
existential types and user defined generalized algebraic data types.
\section{Our contributions}
\subsection*{Extension of Dunfield and Krishnaswami's system}
We have fine-tuned the system for use in practical and user-friendly programming language, by
extending subtyping and inference and adding extra type checking rules for typical language features like \verb+if+
and \verb+let+ expressions, operators and exception handling. We extended their system by adding user defined
generalized algebraic data types. Our approach of creating two representations of each constructor
(one for type checking and one for type inference) in combination with bidirectionality of the original
system provides full expressive power to the programmer, by enabling parametrization with polymorphic types and
treating constructors like functions.
\subsection*{Definition of a language and implementation}
We created a language with modern syntax and practical features like exception handling, handful of primitive types
and standard library with many builtin operators, rich base of IO, utlity, convertion and traditional FP functions.
We implemented interpreter of Bestrafer in Haskell. We put a lot of effort into
creating reliable, useful and easy to use implementation of our language.
To ensure correctness of the implementation we created almost 440 unit tests for the type system.
We payed extra attention to producing readable and helpful type checking error messages.
For example:
\begin{verbatim}
prog.br:4:26
Couldn't match expected type 'Int' with actual type 'Float'
\end{verbatim}
We are also providing hints for some more complex error cases:
\begin{verbatim}
sorting.br:17:3
Type variable not in scope: 'k'
While trying to subtype: '(exists k : N . (Vec k a))' < '(Vec n1~ a~)'
Hint: try using let to unpack '(exists k : N . (Vec k a))'
before using it in the expression of type '(Vec n1~ a~)'
\end{verbatim}
Finally, we provided handful of example Bestrafer codes which showcase language syntax and features.
\chapter{Language description}
\section{Language features}
Bestrafer's syntax was designed to be concise, expressive, readable and beautiful.
It was strongly influenced by Haskell, but modified to be indentation-insensitive for greater
flexibility in writing beautiful code and ease of parsing.
\begin{verbatim}
//Single-line comment
/*
  Multi-line comment
*/

def fac :: Int -> Int
def fac 0 = 1
def fac n = n * fac (n - 1)

def ack :: Int -> Int -> Int
def ack m n = case (m, n) of
  | (0, n) -> n + 1
  | (m, 0) -> ack (m - 1) 1
  | (m, n) -> ack (m - 1) (ack m (n - 1))

def main :: ()
def main =
  printInt (fac 5) `seq`
  printInt (ack 3 1)
\end{verbatim}
Our language supports Haskell-like top-level pattern matching in definitions. Type annotations
for top-level definitions are obligatory due to bidirectionality of the type system.
We use call-by-value evaluation strategy like many mainstream functional languages.
Program is evaluated from the top to the bottom of the source file
(with a minor subtlety described in more detail in the chapter 4). The top-level definitions
are all mutually recursive. One can also define nested functions using \verb+rec+ keyword.
\begin{verbatim}
def fib :: Int -> Int
def fib n =
  rec :: (Int, Int) -> Int -> Int :
    f lasts n = case n of
      | 0 -> fst lasts
      | n -> f (snd lasts, fst lasts + snd lasts) (n - 1)
  in f (0, 1) n
\end{verbatim}

Bestrafer supports all of the typical IO operations including reading and writing files as well as
parsing and printing values of primitive types from and to standard input-output.
IO operations may be performed at any point in program, following the style of
several languages in the ML family. It also supports exception handling with \verb+error+
keyword for throwing errors and \verb+try-catch+ block for catching
user thrown (\verb+RuntimeException+) and builtin (\verb+IOException+,
\verb+ArithmeticException+) exceptions. We can use an optional variable in exception pattern
for extracting the error message.
\begin{verbatim}
def checkPassword :: String -> ()
def checkPassword s =
  if s == "Rammstein" then
    ()
  else
    error: "Password is incorrect"

def main :: ()
def main =
  try:
    let password = getLine () in
    checkPassword password `seq`
    let x = readLnInt () in
    printInt (1000 / x) `seq`
    let filename = getLine () in
    readFile filename |> putStrLn
  catch:
    | IOException e -> putStrLn e
    | ArithmeticException -> putStrLn "Division by zero"
    | RuntimeException e -> putStrLn e
    | Exception e -> putStrLn e
\end{verbatim}

Bestrafer allows the user to define his own generalized algebraic data types (GADTs)
using the \verb+data+ keyword.
\begin{verbatim}
data Maybe 'A where
  | Nothing :: Maybe 'A
  | Just :: 'A -> Maybe 'A

data Value * where
  | F :: Float -> Value Float
  | I :: Int -> Value Int
  | B :: Bool -> Value Bool
\end{verbatim}
Our language also supports defining data types without value constructors, which may be used as annotations in GADTs,
like types \verb+Ok+ and \verb+Fail+ used to annotate type \verb+Either+ in the following example.
\begin{verbatim}
data Ok
data Fail

data Either * 'A 'B where
  | Left  :: 'A -> Either Fail 'A 'B
  | Right :: 'B -> Either Ok 'A 'B
\end{verbatim}
A flagship data type of Bestrafer language is a list indexed by its length, traditionally called \verb+Vec+.
In the following example, we can see usage of the separate kind of natural numbers. We distinguish between
kind of types (\verb+*+) and kind of natural numbers (\verb+N+) to enforce type safety. It is possible to express
natural numbers without addition of a separate kind, by defining type zero: \verb+data Zero+ and successor: \verb+data Succ *+.
However, division into two kinds provides greater clarity and safety. Moreover, we are planning to add to our language
unification modulo equality theory of natural numbers, which will only work on inhabitants of kind \verb+N+.
\begin{verbatim}
data Vec N 'A where
  | []  :: Vec 0 'A
  | (:) :: forall n : N . 'A -> Vec n 'A -> Vec (S n) 'A
\end{verbatim}
Using the above definition we can write \verb+map+ function, which type encodes the proof that the resulting \verb+Vec+ has the same
length as the input one.
\begin{verbatim}
def map :: forall n : N, a : *, b : * .
  (a -> b) ->
  Vec n a ->
  Vec n b
def map _ [] = []
def map f (x : xs) = f x : map f xs
\end{verbatim}
To give programmer full flexibility and expressive power our language also has a standard non-indexed \verb+List+ data type.
\begin{verbatim}
data List 'A where
  | {}  :: List 'A
  | (;) :: 'A -> List 'A -> List 'A
\end{verbatim}

Bestrafer also supports existential types, but unlike in Haskell and OCaml their usage is not tied to data types declarations.
Instead they can be used freely like any other type constructor. The following implementation of a \verb+filter+ function
(taken from Bestrafer's standard library) utilizes existential type to express the fact that we cannot predict length of
the resulting \verb+Vec+. We use \verb+let+ expression to unpack result of recursive call from the existential type, thus
ensuring that the type variable describing length of \verb+tail+ is inserted to the context before the subtyping starts.
\begin{verbatim}
def filter :: forall n : N, a : * .
  (a -> Bool) ->
  Vec n a ->
  exists k : N . Vec k a
def filter _ [] = []
def filter p (x : xs) =
  let tail = filter p xs in
  if p x then
    x : tail
  else
    tail
\end{verbatim}

Quantifiers are always explicit to enforce conscious kind specification and emphasize connection to a type theoretic core.
To articulate this connection even more instead of writing \verb+forall+, \verb+exists+ and \verb+\x -> x+ one can write
$\forall$, $\exists$ and $\lambda$ \verb+x -> x+.
\section{GADT examples}
\subsection*{Matrix algebra}
We can make great use of Bestrafer's indexed \verb+Vec+ type to implement matrix algebra operations.
Now the types provide the proof that the matrix operations that we defined produce results of
correct dimensions and impose restrictions on input arguments which ensure that they also have
proper dimensions.
\begin{verbatim}
def mult :: forall n : N, m : N, k : N .
  Vec (S n) (Vec (S m) Int) ->
  Vec (S m) (Vec (S k) Int) ->
  Vec (S n) (Vec (S k) Int)
def mult a b = map ((flip multVec) b) a

def multVec :: forall n : N, m : N .
  Vec (S n) Int ->
  Vec (S n) (Vec (S m) Int) ->
  Vec (S m) Int
def multVec v m =
  map (foldl1 (\x y -> x + y))
  (map (zipWith (\x y -> x * y) v) (transpose m))

def transpose :: forall n : N, m : N .
  Vec (S n) (Vec (S m) Int) ->
  Vec (S m) (Vec (S n) Int)
def transpose matrix =
  let indices = mapi const (head matrix) in
  map (flip column matrix) indices

def column :: forall n : N, m : N .
  Int ->
  Vec (S n) (Vec (S m) Int) ->
  Vec (S n) Int
def column i = map (nth i)

def nth :: forall n : N, a : * . Int -> Vec (S n) a -> a
def nth 0 (x : xs) = x
def nth _ [x] = x
def nth n (x1 : x2 : xs) = nth (n - 1) (x2 : xs)
\end{verbatim}
One could think that the above functions are only useful for some statically defined values,
since we cannot predict dimensions of \verb+Vec+s which come from IO. But, that is not true!
We can use them in a program that reads matrices from IO, but we have to prove that we handle
all cases of invalid input before passing it into our matrix algebra functions.

\subsection*{Statically typed printf function}
The well-known \verb+printf+ function from the C programming language,
uses a string to provide formating of a printed text. However, this approach
has a major drawback: formated arguments are not statically type checked.
As a result of that, writing \verb+printf("%d", 3.14);+ will print meaningless int,
without emiting any warning or error. That's where the GADTs come to the rescue.
We reimplemented Andrew Kennedy and Claudio Russo's\cite{gadt-oop} solution for that problem, originally written in \verb+C#+.
In the following example, we define \verb+Format+ data type which is used to express intended formating of a
printed string. By chaining constructors together we define type of intended printing function,
which is accumulated in unnamed parameter of the \verb+Format+ data type. When a value of
the type \verb+Format+ is applied to the function \verb+printf+, an appropriate printing function
is built by step by step deconstruction of the \verb+Format+ value. By combining this approach
with the function composition operator (.) (for writing more readable chains of constructors),
we get a neat and type-safe way of pretty-printing values into the standard output.
\begin{verbatim}
data Format * where
  | Str :: forall a : * . Format a -> Format (String -> a)
  | Inr :: forall a : * . Format a -> Format (Int -> a)
  | Flt :: forall a : * . Format a -> Format (Float -> a)
  | Bl  :: forall a : * . Format a -> Format (Bool -> a)
  | Chr :: forall a : * . Format a -> Format (Char -> a)
  | Lit :: forall a : * . String -> Format a -> Format a
  | Eol :: forall a : * . Format a -> Format a
  | End :: Format ()

def printf ::  forall a : * . Format a -> a
def printf End = ()
def printf (Lit s format) = putStr s `seq` printf format
def printf (Eol format) = putStrLn "" `seq` printf format
def printf (Str format) =
  \x -> putStr x `seq` printf format
def printf (Inr format) =
  \x -> (putStr . intToString) x `seq` printf format
def printf (Flt format) =
  \x -> (putStr . floatToString) x `seq` printf format
def printf (Bl  format) =
  \x -> (putStr . boolToString) x `seq` printf format
def printf (Chr format) =
  \x -> putChar x `seq` printf format

def main :: ()
def main =
  putStrLn "What is your name ?" `seq`
  let name = getLine () in
  printf ((Lit "Hello " . Str . Lit "!" . Eol .
           Lit "The answer is: " . Inr . Eol) End) name 42
\end{verbatim}

It is worth mentioning, that it is possible to implement statically typed printf function
whithout using GADTs, utilizing continuation passing style (CPS)\cite{unparsing}.
However, the GADT solution provides better encapsulation of implementation and
is easier to comprehend. We show Bestrafer implementation of the CPS approach in the following example.
\begin{verbatim}
def lit :: forall a : * . String -> (String -> a) -> String -> a
def lit s1 c s2 = c (s2 ^ s1)

def eol :: forall a : * . (String -> a) -> String -> a
def eol c s = c (s ^ "\n")

def inr :: forall a : * . (String -> a) -> String -> Int -> a
def inr c s x = c (s ^ (intToString x))

def flt :: forall a : * . (String -> a) -> String -> Float -> a
def flt c s x = c (s ^ (floatToString x))

def str :: forall a : * . (String -> a) -> String -> String -> a
def str c s1 s2 = c (s1 ^ s2)

def sprintf :: forall a : *, b : * . ((a -> a) -> String -> b) -> b
def sprintf format = format (\x -> x) ""

def main :: ()
def main = putStrLn <| sprintf (flt . eol . inr)  44.0 42
\end{verbatim}

\chapter{Type system}
\section{Dunfield and Krishnaswami's system}
Bestrafer uses an extended version of recent bidirectional type system by Dunfield and Krishnaswami\cite{gadt-popl19}.
Their unique approach enables mixing existential and universal quantifiers in higher-rank polymorphism. This is made possible by
their novel polarized subtyping rule, which fixes the order in which quantifiers are instantiated, making the
problem decidable and keeps the fundamental properties of subtyping, like stability under substitution and transitivity.
Contrary to most mainstream functional languages like Haskell and OCaml,
the usage of existential types in their system is not tied to data types declarations. This means that existential types
do not have to be packaged within another data type; instead they can be used like any other type constructor.
Their system also features a guarded type $P \supset A $ (\textit{$P$ implies $A$})
and an asserting type $A \wedge  P$ (\textit{$A$ with $P$}).
Similarly to Hindley-Milner they distinguish between monotypes and polytypes.
While their system is bidirectional, their approach relies heavily on checking against known type, providing only few inference
rules that eliminate need for most tedious type annotations.
They provide algorithms for type checking, subtyping, checking pattern matching coverage and finally checking and eliminating propositions.
We call the typing judgement principal, if it is not result of guessing. Dunfield and Krishnaswami's system features principality tracking,
where in following rules: \textbf{!} means principal judgement and \cancel{\textbf{!}} or omitted means non-principal.
Information about principality is used, for example, in match coverage algorithm, where propositions are assumed only
for principal judgements.
\subsection*{Typing and subtyping rules}

\section{Our variant of the system}
We made some necessary modification to the type system to make our language useful and user friendly.
First of all we added typing rules for simple types such as
\verb+Int+ or \verb+String+, operators, \verb+if+ statements, \verb+let+ expressions,
\verb+error+ throwing and \verb+try+ - \verb+catch+ blocks, but we omit them in this thesis because
they are not interesting and straightforward. However, it is important to remark, that \verb+let+ expression unpacks the
existential types which is necessary to ensure correct order of inserting type variables to the context while defining
recursive functions. We also added extra inference rules following the earlier work of Dunfield and Krishnaswami\cite{Dunfield13:bidir},
to minize boilerplate type annotations and produce better quality type checking errors. Following
remark of Dunfield and Krishnaswami\cite{gadt-popl19} we extended subtyping to functions and propositional types.
The biggest modification is the introduction of user defined generalized algebraic data types. The last section
of this chapter covers exhaustively typing rules and implementation details of GADTs. %We discarded separate rules for
%\verb+Vec+, treating it like any other GADT.

\subsection*{Types, monotypes and propositions}

We distinguish between types (for clarity sometimes called big types) and monotypes.
Monotypes consist of simplified types (whithout quantification and propositional types) and
inhabitants of kind $\mathbb{N}$ (constructed from zero - \verb+0+ and successor - \verb+S+).
As we can see from the following definition quantification and propositions are restricted to monotypes.
However, our extended subtyping reduces number of programs which would not type check due to this restriction.

\textbf{Kinds:}

\begin{grammar}{\kappa \Coloneqq}{}
  \star \mid \mathbb{N}
\end{grammar}

\textbf{Types:} (big types)

\begin{grammar}{A,B,C\Coloneqq}{}
  \verb+()+ \mid \verb+Bool+ \mid \verb+Int+ \mid \verb+Float+  \mid \verb+Char+ \mid \verb+String+ & simple types\\
  \mid  A_1 \times A_2 \times \dots \times A_n & product\\
  \mid \alpha                           & universal variable\\
  \mid  \hat{\alpha}                    & existential variable\\
  \mid \forall t \colon \kappa. A       & universal quantification\\
  \mid \exists t \colon \kappa. A       & existential quantification\\
  \mid P \supset A                      & guarded type\\
  \mid A \wedge  P                      & asserting type\\
  \mid \mathrm{T}\, \rho_1  \rho_2  \dots \rho_n              & user defined GADT
\end{grammar}

\textbf{Type identifiers:}
$\mathrm{T}$

\textbf{GADT parameters:}

\begin{grammar}{\rho \Coloneqq}{}
  A \mid n                              & type or monotype
\end{grammar}

\textbf{Monotypes:}

\begin{grammar}{t,n\Coloneqq}{}
  0                                & zero\\
  \mid S \, n                              & successor of n\\
  \mid \verb+()+ \mid \verb+Bool+ \mid \verb+Int+ \mid \verb+Float+  \mid \verb+Char+ \mid \verb+String+ & simple types\\
  \mid  t_1 \times t_2 \times \dots \times t_n & product\\
  \mid \alpha                           & universal variable\\
  \mid  \hat{\alpha}                    & existential variable\\
  \mid \mathrm{T}\, t_1  t_2  \dots t_n              & user defined GADT
\end{grammar}

\textbf{Propositions:}

\begin{grammar}{P,Q\Coloneqq}{}
  t = t`
\end{grammar}

\subsection*{Higher-rank polymorphism}
One of the key features of the Dunfield and Krishnaswami's system is higher-rank polymorphism.
Polymorphic types are treated like any other big type so they can be nested arbitrarily
deep. The following example uses higher-rank universal quantification in GADT constructor
to implement Scott's encoding of lists as a two continuations\cite{rankNtypes}.
\begin{verbatim}
data ListS 'A where
  | ListS :: (forall r : * .
             ('A -> ListS 'A -> r) ->r -> r) ->
             ListS 'A

def nil :: forall a : * . ListS a
def nil = ListS (\co ni -> ni)

def cons :: forall a : * . a -> ListS a -> ListS a
def cons x xs = ListS (\co ni -> co x xs)

def uncons :: forall a : *, r : * .
  (a -> ListS a -> r) -> r -> ListS a -> r
def uncons co ni (ListS f) = f co ni
\end{verbatim}
Bestrafer also allows higher-rank existential quantification as the following example shows.
\begin{verbatim}
def heads :: forall n : N, a : * .
  Vec n (exists m : N . Vec (S m) a) ->
  Vec n a
def heads [] = []
def heads (x : xs) = head x : heads xs
\end{verbatim}

\subsection*{Guarded types and asserting types}
Bestrafer supports explicit guarded types $P \supset A $ (\textit{$P$ implies $A$})
and asserting types $A \wedge  P$ (\textit{$A$ with $P$}).
Although the usage of propositions is in most cases implicit and hidden in type checking GADTs,
there are some use cases for propositional types.
The following example uses guarded types to express GADT in continuation passing style\cite{rankNtypes}.

\begin{verbatim}
data SomeC * where
  | SomeC :: forall a : *. (forall r : * .
             (a = Int => Int -> r) ->
             (a = String => String -> r) ->
             (a -> r) -> r) -> SomeC a

def int :: Int -> SomeC Int
def int x = SomeC (\i s o -> i x)

def string :: String -> SomeC String
def string x = SomeC (\i s o -> s x)

def other :: forall a : * . a -> SomeC a
def other x = SomeC (\i s o -> o x)

def unsome :: forall a : *, r : * .
  (Int -> r) ->
  (String -> r) ->
  (a -> r) ->
  SomeC a -> r
def unsome i s o (SomeC f) = f i s o

def main :: ()
def main =
  let x = other 3.14 in
  printInt <| unsome id intFromString floatToInt x
\end{verbatim}

\subsection*{Extended subtyping}
Following remark in Dunfield and Krishnaswami's\cite{gadt-popl19} paper,
we include additional subtyping rules to improve flexibility and expressiveness of the type system.
Without these rules the above example would not work, since we wouldn't be able to subtype
\verb+(Int -> r) +$<$ \verb+(a = Int => Int -> r)+. Rules $A \le^- P \supset B$ and $A \le^+ B \wedge P$
are based on type checking rules for asserting and guarding types.
Rules $P \supset A \le^- B$ and $A \wedge P \le^+ B$ are obtained as a duality of previous two rules.
\subsubsection*{Function subtyping:}
\begin{mathpar}
\inferrule{\Gamma \vdash A' \le^+ A \dashv \Theta \\
           \Theta \vdash [\Theta]B \le^- [\Theta]B' \dashv \Delta}
           {\Gamma \vdash A \rightarrow B \le^- A' \rightarrow B' \dashv \Delta}
\end{mathpar}
\subsubsection*{Propositional types subtyping:}
\begin{mathpar}
\inferrule{\text{$B$ not guarded} \\ \Gamma \vdash P \: \mathit{true} \dashv \Theta \\
           \Theta \vdash [\Theta]A \le^- [\Theta]B \dashv \Delta}
           {\Gamma \vdash P \supset A \le^- B \dashv \Delta} \and
\inferrule{\Gamma, \, _{\blacktriangleright P} / P \dashv \Theta \\
           \Theta \vdash [\Theta]A \le^- [\Theta]B \dashv \Delta , \, _{\blacktriangleright P}, \, \Delta'}
           {\Gamma \vdash A \le^- P \supset B \dashv \Delta} \and
\inferrule{\Gamma, \, _{\blacktriangleright P} / P \dashv \bot}
          {\Gamma \vdash A \le^- P \supset B \dashv \Gamma} \and
\inferrule{\Gamma, \, _{\blacktriangleright P} / P \dashv \Theta \\
           \Theta \vdash [\Theta]A \le^+ [\Theta]B \dashv \Delta , \, _{\blacktriangleright P}, \, \Delta'}
           {\Gamma \vdash A \wedge P \le^+ B \dashv \Delta} \and
\inferrule{\Gamma, \, _{\blacktriangleright P} / P \dashv \bot}
          {\Gamma \vdash A \wedge P \le^+ B \dashv \Gamma} \and \and
\inferrule{\text{$A$ not asserting} \\ \Gamma \vdash P \: \mathit{true} \dashv \Theta \\
           \Theta \vdash [\Theta]A \le^+ [\Theta]B \dashv \Delta}
           {\Gamma \vdash A \le^+ B \wedge P \dashv \Delta} \and
\end{mathpar}
\section{Our contribution - user defined GADTs}

\subsection*{Named and unnamed parameters}
We distinguish between two kinds of parameters in a GADT definition, that is named and unnamed.
In the following definition of data type \verb+Vec+ we utilize both of these kinds:
\begin{verbatim}
data Vec N 'A where
  | []  :: Vec 0 'A
  | (:) :: forall n : N . 'A -> Vec n 'A -> Vec (S n) 'A
\end{verbatim}
One could wonder why do we need named parameters in our type system.
Couldn't we just use unnamed parameters and quantifiers, like in the example below ?
\begin{verbatim}
data Vec N * where
  | []  :: forall a : * . Vec 0 a
  | (:) :: forall n : N, a : * . a -> Vec n a -> Vec (S n) a
\end{verbatim}
It is that we can define \verb+Vec+ like this, but there is a drawback to that approach. Since we use
quantification over \verb+a+, our definition of \verb+Vec+ is restricted to monotypes. Thus, for example, we wouldn't be
able to type check vector of mixed length vectors: \verb+Vec n (exists m : N . Vec m a)+. That's where
named parameters come into play. They are capable of storing big types.
However, that also means that they cannot be involved in propositions, because we only support equations over monotypes.
As we can see, the combination of both kinds
of parameters is essential to provide full expressive power to the programmer.

\subsection*{Building and type checking constructors}
We build GADT representations between parsing and type checking process. We start by checking well-formedness of
constructors. We define well formed constructor in the following manner:

$\mathrm{WFConstr} ::= \mathrm{Universal}$

\begin{grammar}{\mathrm{Universal}\Coloneqq}{}
  \forall \alpha : \kappa \,.\, \mathrm{Universal}
  \mid \mathrm{Arrow}
\end{grammar}

\begin{grammar}{\mathrm{Arrow}\Coloneqq}{}
  A \rightarrow \mathrm{Arrow}
  \mid \mathrm{WFResult}
\end{grammar}\bigskip\\
By $\mathrm{WFResult}$ (well formed result type) we mean the type that matches type signature of currently defined GADT,
where positions of named parameters and kinds of types associated with unnamed parameters also match the type signature.
After that we build two representations of each constructor: template representation which is used when we check constructor
expression against known GADT type and functional which is used in all other cases (namely, partial application and passing
constructor as an argument to a function).

\subsubsection*{Template representation}
For the purpose of template representation we defined type templates, which are types with indexed holes,
which may be filled with any big type or monotype.

\textbf{Type templates:}

\begin{grammar}{A_\dagger,B_\dagger,C_\dagger\Coloneqq}{}
  \verb+()+ \mid \verb+Bool+ \mid \verb+Int+ \mid \verb+Float+  \mid \verb+Char+ \mid \verb+String+ & simple types\\
  \mid  A_{\dagger1} \times A_{\dagger2} \times \dots \times A_{\dagger n} & product\\
  \mid \alpha                                                                                   & universal variable\\
  \mid  \hat{\alpha}                                                                            & existential variable\\
  \mid \forall t \colon \kappa. A_\dagger                                                       & universal quantification\\
  \mid \exists t \colon \kappa. A_\dagger                                                       & existential quantification\\
  \mid P_\dagger \supset A_\dagger                                                              & guarded type\\
  \mid A_\dagger \wedge  P_\dagger                                                              & asserting type\\
  \mid \mathrm{T} \, \rho_{\dagger1}  \rho_{\dagger2}  \dots \rho_{\dagger n}       & user defined GADT \\
  \mid 1,2,3,\dots         & index of GADT parameter
\end{grammar}

\textbf{GADT parameter templates:}

\begin{grammar}{\rho \Coloneqq}{}
  A_\dagger \mid n_\dagger                        & type template or monotype template
\end{grammar}

\textbf{Proposition templates:}

\begin{grammar}{P_\dagger,Q_\dagger\Coloneqq}{}
  t_\dagger = t`_\dagger
\end{grammar}\bigskip\\
We define monotype templates similarly to big type templates, so we omit the formal definition for space reasons.

Template representation consists of list of universally quantified variables, list of propositions and list of constructor
arguments represented as type templates. We substitute named parameters identifiers and unnamed parameters in the result type with
\textit{parameters indices}, which correspond to adequate parameters in the type signature.
We generate propositions automatically based on constructor's result type.

When type checking a constructor, we start by checking if its result type matches the type against which we are type checking.
Then we check the arity of the constructor.
After that we substitute constructor's universally quantified variables with fresh existential variables.
Then we convert arguments' type templates and propositions' templates to types and propositions
by replacing parameters' indices with types and monotypes from checked type's parameters.
Next, we check propositions. Finally, we check constructor's arguments against generated types.
The following, quite lenghty, rule describes that process in the formal way:

\begin{mathpar}
prnc(A, \; p) = \begin{cases}
  \cancel{\textbf{!}} & when \; FEV(A) \neq \emptyset \\
  p                   & when \; FEV(A) = \emptyset
\end{cases}

\inferrule{\mathrm{T}_\mathit{constrName} = \mathrm{T} \\
  \alpha_1, \alpha_2, \dots, \alpha_m \shortleftarrow \mathit{uvars}_\mathit{constrName} \\
  P_{\dagger1}, P_{\dagger2}, \dots, P_{\dagger l} \shortleftarrow \mathit{props}_\mathit{constrName} \\
  A_{\dagger1}, A_{\dagger2}, \dots, A_{\dagger k} \shortleftarrow \mathit{args}_\mathit{constrName} \\
  P'_{\dagger1}, P'_{\dagger2}, \dots, P'_{\dagger l} \leftarrow
  [\hat{\alpha}_1 / \alpha_1, \hat{\alpha}_2 / \alpha_2, \dots, \hat{\alpha}_m / \alpha_m]
  P_{\dagger1}, P_{\dagger2}, \dots, P_{\dagger l}\\
  P_1, P_2, \dots, P_l \shortleftarrow [\rho_1 / 1, \rho_2 / 2, ... , \rho_n / n]
  P'_{\dagger1}, P'_{\dagger2}, \dots, P'_{\dagger l}\\
  A'_{\dagger1}, A'_{\dagger2}, \dots, A'_{\dagger k} \leftarrow
  [\hat{\alpha}_1 / \alpha_1, \hat{\alpha}_2 / \alpha_2, \dots, \hat{\alpha}_m / \alpha_m]
  A_{\dagger1}, A_{\dagger2}, \dots, A_{\dagger k}\\
  A_1, A_2, \dots, A_k \shortleftarrow [\rho_1 / 1, \rho_2 / 2, ... , \rho_n / n]
  A'_{\dagger1}, A'_{\dagger2}, \dots, A'_{\dagger k}\\
  \Gamma \vdash P_1 \: true \dashv \Theta_1\\
  \Theta_1 \vdash [\Theta_1]P_2 \: true \dashv \Theta_2\\
  \cdots \\ \Theta_{l-1} \vdash [\Theta_{l-1}]P_l \: true \dashv \Theta_l\\
  \Theta_l \vdash e_1 \Leftarrow [\Theta_l]A_1 \; prnc(A_1, \: p) \dashv \Delta_1\\
  \Delta_1 \vdash e_2 \Leftarrow [\Delta_1]A_2 \; prnc(A_2, \: p) \dashv \Delta_2\\
  \cdots \\ \Delta_{k-1} \vdash e_k \Leftarrow [\Delta_{k-1}]A_k \; prnc(A_k, \: p) \dashv \Delta_k}
  {\Gamma \vdash \mathit{constrName} \; e_1 \, e_2 \, \dots \, e_k
  \Leftarrow (\mathrm{T} \; \rho_1 \, \rho_2 \, \dots \, \rho_n) \; p \dashv \Delta_k}
\end{mathpar}

\subsubsection*{Functional representation}
Supplementary to the template representation, we represent constructors as a polymorphic functions.
To build functional representation we change named parameters into universally quantified variables.
For example cons of \verb+Vec+:
\begin{verbatim}
(:) :: forall n : N . 'A -> Vec n 'A -> Vec (S n) 'A
\end{verbatim}
is represented as:
\begin{verbatim}
(:) :: forall a : *, n : N . a -> Vec n a -> Vec (S n) a
\end{verbatim}
Since we are using universal quantification on all parameters,
when using functional representation every parameter must by monotype.
This is why we put so much effort into creating template representation based on named
parameters, which is not restricted to monotypes.

\chapter{Remarks on semantics}
Bestrafer is a call-by-value language, with some minor exceptions further discussed below.
We implemented an interpreter of the language that realises big-step semantics.
Formal rules for semantics are typical and rather straightforward so we omit them in this thesis. However, addition
of more complex features like user defined generalized algebraic data types, IO operations and exceptions creates
some subtleties, which we cover in this chapter.
\section{GADT constructors}
Partially applied constructors are changed into (interpreted as) lambda expressions, that take as input missing arguments of the constructor.
For example, if we consider type:
\begin{verbatim}
data Pair 'A 'B where
  | Pair :: 'A -> 'B -> Pair 'A 'B
\end{verbatim}
partial aplication: \verb+Pair 42+ will be changed into \verb+\b -> Pair 42 b+.
\section{Function definitions and evaluation order}
Top-level pattern matching definitions are just syntax sugar for lambda with a match expression inside.
For instance, function definition:
\begin{verbatim}
def map _ [] = []
def map f (x : xs) = f x : map f xs
\end{verbatim}
will be desugared into:
\begin{verbatim}
\x0 x1 -> case (x0, x1) of
  | (_, []) -> []
  | (f, x : xs) -> f x : map f xs
\end{verbatim}

The top-level definitions are all mutually recursive and each of them is evaluated once, starting from the beginning
down to the end of the source file. This may raise a question, what happens if some function uses the definition which is located
further in the source file. In this situation the further definition will be evaluated at the time when it was called,
its value will be remembered and it won't be evaluated for the second time.
Another concern is what would happend in the previous situation if second function would throw an error and the first function would
handle it with a \verb+try-catch+ block. Because the further definition failed to evaluate we treat it as not evaluated and try to evaluate it
on its next use or at the top-level.

\chapter{Discussion and future work}
%Bideriactional type checking is an elegant and practical method of imlementing type systems with GADTs, existential types and higher-rank polymorphism.
%Moreover, it produces better quality type errors and scales well with new features added to the language. Since top-level type annotations are considered
%good practice and help to document the code, bidirectional type system does not require much addiotional effort from the programmer.
%Dunfield and Krishnaswami's system\cite{gadt-popl19} proves to perform well in the practical programming language implementation.
%Our extension of user defined GADTs fully utylizes bidirectional nature of their type system, allowing parametrization with polymorphic types and treating
%constructors as functions.
%
\section{Unification modulo equality theory of natural numbers}
We intend to extend the type system with unification modulo equality theory of natural numbers.
This extension will allow to fully express the type of the append function on \verb+Vec+:
\begin{verbatim}
def append :: forall n : N, m : N, a : * .
  Vec n a ->
  Vec m a ->
  Vec (n + m) a
def append [] ys = ys
def append (x : xs) ys = x : append xs ys
\end{verbatim}
Instead of using existential as the funcion return type:
\begin{verbatim}
def append :: forall n : N, m : N, a : * .
  Vec n a ->
  Vec m a ->
  exists k : N . Vec k a
def append [] ys = ys
def append (x : xs) ys = let tail = append xs ys in x : tail
\end{verbatim}
With that extension we will obtain programming language with similar capabilities as
Dependent ML\cite{DependentML}. By using equality theory we will get intuitive operations
on types of kind $\mathbb{N}$, in contrast to, for example, quite clumsy arithmetic
defined with Haskell's type families.
\section{Automatically unpacking existential quantifiers}
In our language we have to use \verb+let+ expressions to unpack existential quantifiers.
This is needed in order to ensure that type variables are inserted into the environment in the correct order.
However, this may be counterintuitive and difficult to understand at the first time, thus
we would like to implement automatic unpacking of existential quantifiers.
Modified transformation to A-normal form before type checking seem to be promising approach to that problem.
\section{Compiler}
We plan to implement industry-grade compiler for one of the mainstream infrastructures like .NET or JVM.
Another interesting option for further development would be a front-end web development world,
namely implementing transpiler to JavaScript or compiler to web assembly.
In both of these paths the essential part would be to implement elegant and convenient integration
with standard libraries of these platforms.

%%%%% BIBLIOGRAFIA

\bibliographystyle{unsrt}
\bibliography{biblo.bib}

\end{document}
